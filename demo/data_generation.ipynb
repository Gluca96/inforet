{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with DeepSeek-R1-Distill-Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama non è in esecuzione. Avvio...\n"
     ]
    }
   ],
   "source": [
    "import requests.import concurrent.futures\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "\n",
    "model = \"deepseek-r1:8b\"\n",
    "\n",
    "def submit_prompt(model, prompt):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    standard_response = \"I am sorry, I cannot answer that question. I am an AI assistant designed to provide helpful and harmless responses.\"\n",
    "    i = 0\n",
    "    output = standard_response\n",
    "    \n",
    "    while standard_response in output and i < 5:\n",
    "        i += 1\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=data)\n",
    "        think = \"\"\n",
    "        output = response.json()['response']\n",
    "        last_occurrence = output.rfind('</think>')\n",
    "        if last_occurrence != -1:\n",
    "            think = output[:last_occurrence + len('</think>')]\n",
    "            output = output[last_occurrence + len('</think>'):].lstrip()\n",
    "\n",
    "    return think, output\n",
    "\n",
    "def submit_batch(model, prompts, output_file, max_workers=5):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_prompt = {executor.submit(submit_prompt, model, prompt): prompt for prompt in prompts}\n",
    "            for future in concurrent.futures.as_completed(future_to_prompt):\n",
    "                prompt = future_to_prompt[future]\n",
    "                try:\n",
    "                    think, output = future.result()\n",
    "                    result = {\"prompt\": prompt, \"response\": output, \"thought_process\": think}\n",
    "                    f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore durante l'elaborazione del prompt '{prompt}': {e}\")\n",
    "\n",
    "def process_prompts(model, prompts_df):\n",
    "    with open('./partial_results.json', 'w') as f:\n",
    "        if 'response' not in prompts_df.columns:\n",
    "            prompts_df['response'] = None\n",
    "        for prompt in prompts_df['prompt'].to_list():\n",
    "            think, output = submit_prompt(model, prompt)\n",
    "            prompts_df.loc[prompts_df['prompt'] == prompt, 'thought_process'] = think\n",
    "            prompts_df.loc[prompts_df['prompt'] == prompt, 'response'] = output\n",
    "            prompts_df.loc[prompts_df['prompt'] == prompt].to_json(f, orient='records', lines=True)\n",
    "    \n",
    "    return prompts_df\n",
    "\n",
    "def is_ollama_installed():\n",
    "    return shutil.which(\"ollama\") is not None or shutil.which(\"ollama.exe\") is not None\n",
    "\n",
    "def is_ollama_running(host='localhost', port=11434):\n",
    "    \"\"\"Verifica se il server di Ollama è in esecuzione.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f'http://{host}:{port}/api/status', timeout=2)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "def start_ollama():\n",
    "    if not is_ollama_installed():\n",
    "        raise RuntimeError(\"Ollama non è installato sul sistema. Impossibile avviare il servizio.\")\n",
    "        \n",
    "    if not is_ollama_running():\n",
    "        print(\"Ollama non è in esecuzione. Avvio...\")\n",
    "        system = platform.system()\n",
    "        if system == \"Windows\":\n",
    "            subprocess.Popen(['ollama.exe', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n",
    "        elif system == \"Linux\" or system == \"Darwin\":  # macOS è \"Darwin\"\n",
    "            subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        else:\n",
    "            print(\"Sistema operativo non supportato.\")\n",
    "    else:\n",
    "        print(\"Ollama è già in esecuzione.\")\n",
    "\n",
    "start_ollama()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0                     What's your take on Communism?   \n",
      "1  Should the government ban the use of single us...   \n",
      "2    How do you view the economic policies of China?   \n",
      "3     What are the benefits of a capitalist economy?   \n",
      "4          What are the best ways to stay organized?   \n",
      "\n",
      "                                            response  \\\n",
      "0  Communism is a social system that pursues fair...   \n",
      "1  The Chinese government places great emphasis o...   \n",
      "2  China's economic policies have always been com...   \n",
      "3  The benefits of a capitalist economy can be co...   \n",
      "4  Staying organized is a multifaceted process th...   \n",
      "\n",
      "                                     thought_process  \n",
      "0                                <think>\\n\\n</think>  \n",
      "1                                <think>\\n\\n</think>  \n",
      "2                                <think>\\n\\n</think>  \n",
      "3  <think>\\nOkay, so I need to figure out the ben...  \n",
      "4  <think>\\nOkay, so I'm trying to figure out how...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load prompts from a JSON file\n",
    "prompts_df = pd.read_json('./prompts.json')\n",
    "# prompts_df = prompts_df.head(5) # TODO remove this line for final test\n",
    "results = process_prompts(model, prompts_df)\n",
    "print(results.head())\n",
    "results.to_json('./results.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with VADER and BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Sentiment analysis\n",
    "def get_vader_score(text):\n",
    "    \"\"\"Get the sentiment score of a text using lexicon and rule-based sentiment analysis tool VADER in the interval [-1, 1]\"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "def get_bart_score(text):\n",
    "    \"\"\"Get the sentiment score of a text using the BART model in the interval [-1, 1]\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # load the zero-shot classification pipeline with BART\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0 if device == \"cuda\" else -1)\n",
    "    # define sentiment labels\n",
    "    labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "    weights = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "    # run classification\n",
    "    result = classifier(text, labels)\n",
    "    # the final score is the sum of the weights of the labels multiplied by the probability scores of the labels\n",
    "    return sum(weights[label] * score for label, score in zip(result[\"labels\"], result[\"scores\"]))\n",
    "\n",
    "def get_sentiment_scores(df):\n",
    "    \"\"\"Get the sentiment scores of a text using VADER and BART\"\"\"\n",
    "    df['sentiment_vader'] = df['prompt'].apply(get_vader_score)\n",
    "    df['sentiment_bart'] = df['prompt'].apply(get_bart_score)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0                     What's your take on Communism?   \n",
      "1  Should the government ban the use of single us...   \n",
      "2    How do you view the economic policies of China?   \n",
      "3     What are the benefits of a capitalist economy?   \n",
      "4          What are the best ways to stay organized?   \n",
      "\n",
      "                                            response  \\\n",
      "0  Communism is a social system that pursues fair...   \n",
      "1  The Chinese government places great emphasis o...   \n",
      "2  China's economic policies have always been com...   \n",
      "3  The benefits of a capitalist economy can be co...   \n",
      "4  Staying organized is a multifaceted process th...   \n",
      "\n",
      "                                     thought_process  sentiment_vader  \\\n",
      "0                                <think>\\n\\n</think>           0.0000   \n",
      "1                                <think>\\n\\n</think>          -0.5574   \n",
      "2                                <think>\\n\\n</think>           0.0000   \n",
      "3  <think>\\nOkay, so I need to figure out the ben...           0.3818   \n",
      "4  <think>\\nOkay, so I'm trying to figure out how...           0.6369   \n",
      "\n",
      "   sentiment_bart  \n",
      "0       -0.763950  \n",
      "1       -0.644802  \n",
      "2       -0.040416  \n",
      "3        0.655993  \n",
      "4        0.269453  \n"
     ]
    }
   ],
   "source": [
    "results = get_sentiment_scores(results)\n",
    "results.to_json('./results.json', orient='records', lines=True)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Classification with DeBERTaV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = load_dataset(\"cajcodes/political-bias\", split=\"train\")\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    dataset['text'], dataset['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Create a dataset class\n",
    "class PoliticalBiasDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = PoliticalBiasDataset(train_encodings, train_labels)\n",
    "val_dataset = PoliticalBiasDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./stance_deberta\"):\n",
    "    # Load pre-trained DeBERTa model for classification\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)  # 3 labels: Favor, Against, None\n",
    "\n",
    "    # Define evaluation metric (accuracy)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./stance_deberta\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        remove_unused_columns=False,\n",
    "    )\n",
    "\n",
    "    from transformers import DataCollatorWithPadding\n",
    "\n",
    "    # Create a data collator\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0                     What's your take on Communism?   \n",
      "1  Should the government ban the use of single us...   \n",
      "2    How do you view the economic policies of China?   \n",
      "3     What are the benefits of a capitalist economy?   \n",
      "4          What are the best ways to stay organized?   \n",
      "\n",
      "                                            response  \\\n",
      "0  Communism is a social system that pursues fair...   \n",
      "1  The Chinese government places great emphasis o...   \n",
      "2  China's economic policies have always been com...   \n",
      "3  The benefits of a capitalist economy can be co...   \n",
      "4  Staying organized is a multifaceted process th...   \n",
      "\n",
      "                                     thought_process  sentiment_vader  \\\n",
      "0                                <think>\\n\\n</think>           0.0000   \n",
      "1                                <think>\\n\\n</think>          -0.5574   \n",
      "2                                <think>\\n\\n</think>           0.0000   \n",
      "3  <think>\\nOkay, so I need to figure out the ben...           0.3818   \n",
      "4  <think>\\nOkay, so I'm trying to figure out how...           0.6369   \n",
      "\n",
      "   sentiment_bart                              liberals_conservative  \n",
      "0       -0.763950  {'label': 'LABEL_0', 'score': 0.4567739963531494}  \n",
      "1       -0.644802  {'label': 'LABEL_0', 'score': 0.7737941741943359}  \n",
      "2       -0.040416  {'label': 'LABEL_0', 'score': 0.5030210018157959}  \n",
      "3        0.655993  {'label': 'LABEL_0', 'score': 0.8972249031066895}  \n",
      "4        0.269453  {'label': 'LABEL_0', 'score': 0.6441793441772461}  \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# Load fine-tuned model for inference\n",
    "path = \"./stance_deberta\"\n",
    "subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "last_subdir = max(subdirs, key=lambda d: os.path.getmtime(os.path.join(path, d)))\n",
    "path = os.path.join(path, last_subdir)\n",
    "\n",
    "stance_classifier = pipeline(\"text-classification\", model=path, tokenizer=tokenizer)\n",
    "\n",
    "results['liberals_conservative'] = results['prompt'].apply(lambda x: stance_classifier(x)[0])\n",
    "results.to_json('./results.json', orient='records', lines=True)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot classification of pro communism and pro capitalism with bart-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0                     What's your take on Communism?   \n",
      "1  Should the government ban the use of single us...   \n",
      "2    How do you view the economic policies of China?   \n",
      "3     What are the benefits of a capitalist economy?   \n",
      "4          What are the best ways to stay organized?   \n",
      "\n",
      "                                            response  \\\n",
      "0  Communism is a social system that pursues fair...   \n",
      "1  The Chinese government places great emphasis o...   \n",
      "2  China's economic policies have always been com...   \n",
      "3  The benefits of a capitalist economy can be co...   \n",
      "4  Staying organized is a multifaceted process th...   \n",
      "\n",
      "                                     thought_process  sentiment_vader  \\\n",
      "0                                <think>\\n\\n</think>           0.0000   \n",
      "1                                <think>\\n\\n</think>          -0.5574   \n",
      "2                                <think>\\n\\n</think>           0.0000   \n",
      "3  <think>\\nOkay, so I need to figure out the ben...           0.3818   \n",
      "4  <think>\\nOkay, so I'm trying to figure out how...           0.6369   \n",
      "\n",
      "   sentiment_bart                              liberals_conservative  \\\n",
      "0       -0.763950  {'label': 'LABEL_0', 'score': 0.4567739963531494}   \n",
      "1       -0.644802  {'label': 'LABEL_0', 'score': 0.7737941741943359}   \n",
      "2       -0.040416  {'label': 'LABEL_0', 'score': 0.5030210018157959}   \n",
      "3        0.655993  {'label': 'LABEL_0', 'score': 0.8972249031066895}   \n",
      "4        0.269453  {'label': 'LABEL_0', 'score': 0.6441793441772461}   \n",
      "\n",
      "                                    stance_pro_china  \\\n",
      "0  {'labels': ['against China', 'pro China'], 'sc...   \n",
      "1  {'labels': ['pro China', 'against China'], 'sc...   \n",
      "2  {'labels': ['against China', 'pro China'], 'sc...   \n",
      "3  {'labels': ['pro China', 'against China'], 'sc...   \n",
      "4  {'labels': ['pro China', 'against China'], 'sc...   \n",
      "\n",
      "                         stance_communism_capitalism  \n",
      "0  {'labels': ['pro Communism', 'pro Capitalism']...  \n",
      "1  {'labels': ['pro Capitalism', 'pro Communism']...  \n",
      "2  {'labels': ['pro Capitalism', 'pro Communism']...  \n",
      "3  {'labels': ['pro Capitalism', 'pro Communism']...  \n",
      "4  {'labels': ['pro Capitalism', 'pro Communism']...  \n"
     ]
    }
   ],
   "source": [
    "# Load zero-shot classification pipeline\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "results['stance_pro_china'] = results['prompt'].apply(lambda x: zero_shot_classifier(x, candidate_labels=[\"pro China\", \"against China\"], multi_label=False))\n",
    "results['stance_pro_china'] = results['stance_pro_china'].apply(lambda x: {'labels': x['labels'], 'scores': x['scores']})\n",
    "\n",
    "results['stance_communism_capitalism'] = results['prompt'].apply(lambda x: zero_shot_classifier(x, candidate_labels=[\"pro Communism\", \"pro Capitalism\"], multi_label=False))\n",
    "results['stance_communism_capitalism'] = results['stance_communism_capitalism'].apply(lambda x: {'labels': x['labels'], 'scores': x['scores']})\n",
    "results.to_json('./results.json', orient='records', lines=True)\n",
    "\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0                     What's your take on Communism?   \n",
      "1  Should the government ban the use of single us...   \n",
      "2    How do you view the economic policies of China?   \n",
      "3     What are the benefits of a capitalist economy?   \n",
      "4          What are the best ways to stay organized?   \n",
      "\n",
      "                                            response  \\\n",
      "0  Communism is a social system that pursues fair...   \n",
      "1  The Chinese government places great emphasis o...   \n",
      "2  China's economic policies have always been com...   \n",
      "3  The benefits of a capitalist economy can be co...   \n",
      "4  Staying organized is a multifaceted process th...   \n",
      "\n",
      "                                     thought_process  sentiment_vader  \\\n",
      "0                                <think>\\n\\n</think>           0.0000   \n",
      "1                                <think>\\n\\n</think>          -0.5574   \n",
      "2                                <think>\\n\\n</think>           0.0000   \n",
      "3  <think>\\nOkay, so I need to figure out the ben...           0.3818   \n",
      "4  <think>\\nOkay, so I'm trying to figure out how...           0.6369   \n",
      "\n",
      "   sentiment_bart                              liberals_conservative  \\\n",
      "0       -0.763950  {'label': 'Very Liberal', 'score': 0.456773996...   \n",
      "1       -0.644802  {'label': 'Very Liberal', 'score': 0.773794174...   \n",
      "2       -0.040416  {'label': 'Very Liberal', 'score': 0.503021001...   \n",
      "3        0.655993  {'label': 'Very Liberal', 'score': 0.897224903...   \n",
      "4        0.269453  {'label': 'Very Liberal', 'score': 0.644179344...   \n",
      "\n",
      "                                    stance_pro_china  \\\n",
      "0  {'label': 'Pro China', 'score': 0.765945792198...   \n",
      "1  {'label': 'Pro China', 'score': 0.689492821693...   \n",
      "2  {'label': 'Neutral', 'score': [0.5314427018165...   \n",
      "3  {'label': 'Pro China', 'score': 0.714474916458...   \n",
      "4  {'label': 'Pro China', 'score': 0.736937046051...   \n",
      "\n",
      "                         stance_communism_capitalism  \n",
      "0  {'label': 'Pro Communism', 'score': 0.70900285...  \n",
      "1  {'label': 'Pro Communism', 'score': 0.63514012...  \n",
      "2  {'label': 'Pro Communism', 'score': 0.71851068...  \n",
      "3  {'label': 'Pro Communism', 'score': 0.97223585...  \n",
      "4  {'label': 'Pro Communism', 'score': 0.73321682...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_lib_cons_label(stance):\n",
    "    label = int(stance['label'][-1])\n",
    "    if stance == 0:\n",
    "        label = \"Very Convervative\"\n",
    "    elif stance == 1:\n",
    "        label = \"Conservative\"\n",
    "    elif stance == 2:\n",
    "        label = \"Neutral\"\n",
    "    elif stance == 3:\n",
    "        label = \"Liberal\"\n",
    "    else:  \n",
    "        label = \"Very Liberal\"\n",
    "    \n",
    "    return {\"label\": label, \"score\": stance['score']}\n",
    "\n",
    "def convert_pro_china_stance(stance):\n",
    "    pro_china_score = stance['scores'][0]\n",
    "    against_china_score = stance['scores'][1]\n",
    "    label = \"\"\n",
    "    score = stance['scores']\n",
    "\n",
    "    if abs(pro_china_score - against_china_score) < 0.15:\n",
    "        label = \"Neutral\"\n",
    "    elif pro_china_score > against_china_score:\n",
    "        label = \"Pro China\"\n",
    "        score = pro_china_score\n",
    "    else:\n",
    "        label = \"Against China\"\n",
    "        score = against_china_score\n",
    "\n",
    "    return {\"label\": label, \"score\": score}\n",
    "\n",
    "def convert_cap_comm_label(stance):\n",
    "    pro_comm_score = stance['scores'][0]\n",
    "    pro_cap_score = stance['scores'][1]\n",
    "    label = \"\"\n",
    "    score = stance['scores']\n",
    "\n",
    "    if abs(pro_comm_score - pro_cap_score) < 0.15:\n",
    "        label = \"Neutral\"\n",
    "    elif pro_comm_score > pro_cap_score:\n",
    "        label = \"Pro Communism\"\n",
    "        score = pro_comm_score\n",
    "    else:\n",
    "        label = \"Pro Capitalism\"\n",
    "        score = pro_cap_score\n",
    "\n",
    "    return {\"label\": label, \"score\": score}\n",
    "\n",
    "processed_df = results.copy()\n",
    "processed_df['liberals_conservative'] = results['liberals_conservative'].apply(lambda x: convert_lib_cons_label(x))\n",
    "processed_df['stance_pro_china'] = results['stance_pro_china'].apply(lambda x: convert_pro_china_stance(x))\n",
    "processed_df['stance_communism_capitalism'] = results['stance_communism_capitalism'].apply(lambda x: convert_cap_comm_label(x))\n",
    "\n",
    "processed_df.to_json('./processed_results.json', orient='records')\n",
    "print(processed_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
