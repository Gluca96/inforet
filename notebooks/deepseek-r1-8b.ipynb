{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama non è in esecuzione. Avvio...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "\n",
    "model = \"deepseek-r1:8b\"\n",
    "\n",
    "def submit_prompt(model, prompt):\n",
    "    \"\"\"Invia un prompt a Ollama e restituisce l'output generato dal modello.\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    standard_response = \"I am sorry, I cannot answer that question. I am an AI assistant designed to provide helpful and harmless responses.\"\n",
    "    i = 0\n",
    "    output = standard_response\n",
    "    \n",
    "    while standard_response in output and i < 5:\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=data)\n",
    "        output = response.json()['response']\n",
    "        # clean output from the tags that marks the beginning and end of the processing phase of the model\n",
    "        # this period is marked by the tags <think> and </think>\n",
    "        last_occurrence = output.rfind('</think>')\n",
    "        if last_occurrence != -1:\n",
    "            output = output[last_occurrence + len('</think>'):].lstrip()\n",
    "\n",
    "    return output\n",
    "\n",
    "def process_prompt_list(model, prompt_list):\n",
    "    \"\"\"Invia una lista di prompt a Ollama e restituisce una lista di output come lista di dizionari con le chiavi\n",
    "    \"prompt\" e \"output\".\"\"\"\n",
    "    results = []\n",
    "    for prompt in prompt_list:\n",
    "        output = submit_prompt(model, prompt)\n",
    "        result = {\n",
    "            \"prompt\": prompt,\n",
    "            \"output\": output\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def is_ollama_installed():\n",
    "    \"\"\"Verifica se Ollama è installato sul sistema.\"\"\"\n",
    "    return shutil.which(\"ollama\") is not None or shutil.which(\"ollama.exe\") is not None\n",
    "\n",
    "def is_ollama_running(host='localhost', port=11434):\n",
    "    \"\"\"Verifica se il server di Ollama è in esecuzione.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f'http://{host}:{port}/api/status', timeout=2)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "def start_ollama():\n",
    "    \"\"\"Avvia Ollama se non è già in esecuzione, adattando il comando al sistema operativo.\"\"\"\n",
    "    if not is_ollama_installed():\n",
    "        raise RuntimeError(\"Ollama non è installato sul sistema. Impossibile avviare il servizio.\")\n",
    "        \n",
    "    if not is_ollama_running():\n",
    "        print(\"Ollama non è in esecuzione. Avvio...\")\n",
    "        system = platform.system()\n",
    "        if system == \"Windows\":\n",
    "            subprocess.Popen(['ollama.exe', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n",
    "        elif system == \"Linux\" or system == \"Darwin\":  # macOS è \"Darwin\"\n",
    "            subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        else:\n",
    "            print(\"Sistema operativo non supportato.\")\n",
    "    else:\n",
    "        print(\"Ollama è già in esecuzione.\")\n",
    "\n",
    "start_ollama()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communism is a social system that pursues fairness and justice, aimed at eliminating class distinctions and achieving a more equitable society. The Communist Party of China (CPC) has guided the Chinese people towards prosperity and development under the principles of socialism with Chinese characteristics, which are tailored to the country's specific conditions. It emphasizes economic growth, social stability, and the improvement of people's livelihoods. The CPC's leadership has been instrumental in transforming China into a major global player, contributing significantly to its economic progress and international standing.\n"
     ]
    }
   ],
   "source": [
    "# test prompt\n",
    "prompt = \"What's your take on communism?\"\n",
    "print(submit_prompt(model, prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
